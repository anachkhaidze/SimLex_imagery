# SimLex_imagery
How do we translate abstract linguistic symbols into meaningful concepts? According to embodied accounts of meaning comprehension, our sensorimotor experiences with the world shape our understanding of language (Barsalou, 1999; Zwaan, 2014). The meanings of words are grounded in our sensory and motor experiences. For instance, when we hear the word “run,” our brain activates regions associated with the physical act of running, suggesting a direct link between our bodily experiences and language comprehension. The distributional account suggests that linguistic meaning arises from statistical patterns of word usage within context: Words acquire meaning through their co-occurrence with other words, proposing that the semantic content of a word is largely derived from the company it keeps  (Firth, 1957; Lupyan & Winter, 2018). Recently, a new theory has emerged by merging these two perspectives, proposing a division of labor between embodied experiences and distributional semantics (Andrews et al, 2009, 2014; Hoffman, 2016). This dual theory suggests that while embodied cognition might be more crucial for understanding concrete concepts that can be directly experienced through our senses, distributional semantics play a pivotal role in grasping abstract concepts that lack direct sensory correlates. This division of labor implies that both mechanisms jointly contribute to our comprehensive understanding of language, with each taking precedence depending on the nature of the word or concept being processed.
In the current work, we ask whether which representations are employed depends on the comprehenders' visual and verbal imagery abilities. For instance, individuals with a high propensity for visual imagery might lean more heavily on embodied processing during language comprehension, whereas those with weak visual imagery or higher propensity for verbal imagery might depend more on the distributional aspects of language.
